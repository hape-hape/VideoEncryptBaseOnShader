<html>

<head>
    <title>HLS播放</title>
    <script src="https://vjs.zencdn.net/7.4.1/video.js"></script>
    <link href="https://vjs.zencdn.net/7.4.1/video-js.css" rel="stylesheet">
    <style type="text/css">
    </style>
</head>

<body>
    <!-- 纯净拉流 -->
    <h2>纯净直播流1</h2>
    <video-js id="stream-video1" width="1280" height="720" class="vjs-default-skin" controls>
        <source
            src="https://d1--cn-gotcha101.bilivideo.com/live-bvc/334644/live_7734200_bs_7236416_1500.m3u8?expires=1684253692&len=0&oi=827633949&pt=h5&qn=150&trid=10035a71d53b4f8b40f3b441a2c9808e56bf&sigparams=cdn,expires,len,oi,pt,qn,trid&cdn=cn-gotcha01&sign=29abdb34280abd39cd865cd52fe176ea&sk=8850a2b8817f9dbc872b6389c642a426&p2p_type=0&sl=10&free_type=0&mid=0&pp=rtmp&source=onetier&trace=10&site=d471bf630851c115b2af5f07450a540d&order=1"
            type="application/x-mpegURL">
    </video-js>
    <h2>纯净直播流2</h2>
    <video-js id="stream-video2" width="1280" height="720" class="vjs-default-skin" controls>
        <source
            src="https://d1--cn-gotcha101.bilivideo.com/live-bvc/249439/live_474595627_50840492_1500.m3u8?expires=1684265012&len=0&oi=827633949&pt=h5&qn=150&trid=10038fd26213fa4a4ede8d15f2b0bb6eb439&sigparams=cdn,expires,len,oi,pt,qn,trid&cdn=cn-gotcha01&sign=a54edecf5a69e81f3af02f1dd98ae87b&sk=1304f646dfeb4df8b6e7ff33c167d3ad52dc28d2b434c49b202f46923d102069&p2p_type=0&sl=9&free_type=0&mid=0&pp=rtmp&source=onetier&trace=10&site=b0ab15ca65cfcca5785fd6c575fa5c8f&order=1"
            type="application/x-mpegURL">
    </video-js>

    <h2>直播流1的canvas</h2>
    <canvas id="canvas-video1"></canvas>
    <h2>直播流2的canvas</h2>
    <canvas id="canvas-video2"></canvas>

    <!-- 通常是加密后 -->
    <h2>正向处理结果</h2>
    <canvas id="forward-video1"></canvas>
    <!-- 通常是解密后 -->
    <h2>反向处理结果(已模拟传输时损失)</h2>
    <canvas id="backward-video1">
    </canvas>




    <script>
        const shiftrowsnum=3//每隔多少行显示一行视频1画面
        const maxcolorshiftpercent=0.8//偏移的颜色最多占据剩余颜色空间的百分点
        /**
        * 正向处理像素信息（加密）
        * @param {Array} imagedatalist 一个包含两个图像的数组，分别是直播流1和直播流2的图像
        * @returns 一个图像
        */
        function forwardProcessData(imagedatalist) {
            let imagedata1 = imagedatalist[0]
            let imagedata2 = imagedatalist[1]

            // 每四行，把视频2的第一行和第二行第三行放到视频1
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += shiftrowsnum) {
                    for(let s=0;s<shiftrowsnum-1;s+=1){
                        setPixel(imagedata1, j+s, i, getPixel(imagedata2, j+s, i))
                    }
                }
            }
            // 混淆视频内容
            for (let j = 0; j < imagedata1.height; j += shiftrowsnum) {
                shiftRight(j+shiftrowsnum-1,imagedata1)
            }
            // 每4行，把视频1的第4行的数据按照当前第3行剩余的颜色空间作百分比放缩(限制最多偏移0.6)，加上第3行的基数，放到第4行
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += shiftrowsnum) {
                    let pixel1 = getPixel(imagedata1, j+shiftrowsnum-2, i)
                    let pixel2 = getPixel(imagedata1, j+shiftrowsnum-1, i)//视频1要隐藏的第4行
                    let pixel4 = [0, 0, 0, 0]
                    for (let k = 0; k < 4; k += 1) {
                        pixel4[k] = Math.floor(( pixel2[k] / 255 ) * ( (255 - pixel1[k])* maxcolorshiftpercent ) + pixel1[k])
                    }
                    setPixel(imagedata1, j+shiftrowsnum-1, i, pixel4)
                }
            }





            return imagedata1
        }


        /**
         * 中间处理像素信息，模拟传输过程
         * @param {Array} imagedatalist 一个包含一个图像的数组，是正向处理后的图像
         * @returns 一个图像
         */
        function middleProcessData(imagedatalist){
            let imagedata1=imagedatalist[0]

            // 加点噪声
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += 1) {
                    let random = Math.random()
                    if (random < 0.0001) {
                        setPixel(imagedata1, j, i, [255, 255, 255, 255])
                    }
                }
            }
            // 在随机的区域偏色
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += 1) {
                    let random = Math.random()
                    if (random < 0.001) {
                        const randomblur = Math.floor(Math.random() * 10)
                        const index1 = (j * imagedata1.width + i) * 4
                        setPixel(imagedata1, j, i, [imagedata1.data[index1] + randomblur, imagedata1.data[index1 + 1] + randomblur, imagedata1.data[index1 + 2] + randomblur, imagedata1.data[index1 + 3] + randomblur])
                    }
                }
            }
            // 在随机的区域取附近的点的值代替
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += 1) {
                    let random = Math.random()
                    if (random < 0.001) {
                        let randomblur = Math.floor(Math.random() * 10)
                        let randomx = Math.floor(Math.random() * 10)
                        let randomy = Math.floor(Math.random() * 10)
                        let index2 = ((j + randomy) * imagedata1.width + i + randomx) * 4
                        try {
                            setPixel(imagedata1, j, i, [imagedata1.data[index2], imagedata1.data[index2 + 1], imagedata1.data[index2 + 2], imagedata1.data[index2 + 3]])
                        } catch (error) {
                            
                        }
                        
                    }
                }
            }

            return imagedata1
        }

        /**
         * 反向处理像素信息（解密）
         * @param {Array} imagedatalist 一个包含一个图像的数组，是传输过后的正向处理后的图像
         * @returns 一个图像
         */
        function backwardProcessData(imagedatalist) {
            let imagedata1 = imagedatalist[0]
            // 每4行，把视频1的第4行的数据减去第三行的数据，按照放缩比例百分比放缩回255，放到第4行
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += shiftrowsnum) {
                    let pixel1 = getPixel(imagedata1, j+shiftrowsnum-2, i)//视频1的第3行
                    let pixel2 = getPixel(imagedata1, j+shiftrowsnum-1, i)//视频1隐藏的第4行
                    let pixel4 = [0, 0, 0, 0]
                    for (let k = 0; k < 4; k += 1) {
                        pixel4[k] = Math.floor((pixel2[k]-pixel1[k])/((255-pixel1[k])*maxcolorshiftpercent)*255)
                    }
                    // 否则这一位是NaN
                    pixel4[3]=255
                    setPixel(imagedata1, j+shiftrowsnum-1, i, pixel4)
                }
            }
            // 混淆视频内容
            for (let j = 0; j < imagedata1.height; j += shiftrowsnum) {
                shiftLeft(j+shiftrowsnum-1,imagedata1)
            }
            // 每4行，用第四行数据替换前三行
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += shiftrowsnum) {
                    let pixel1 = getPixel(imagedata1, j+shiftrowsnum-1, i)
                    for(let s=0;s<shiftrowsnum-1;s+=1){
                        setPixel(imagedata1, j+s, i, pixel1)
                    }
                }
            }

            return imagedata1
        }

        function getPixel(imagedata, row, col) {
            let index = (row * imagedata.width + col) * 4
            let pixel = [imagedata.data[index], imagedata.data[index + 1], imagedata.data[index + 2], imagedata.data[index + 3]]
            return pixel
        }

        function setPixel(imagedata, row, col, pixel){
            let index = (row * imagedata.width + col) * 4
            imagedata.data[index] = pixel[0]
            imagedata.data[index + 1] = pixel[1]
            imagedata.data[index + 2] = pixel[2]
            imagedata.data[index + 3] = pixel[3]
        }
        // 向右偏移
        function shiftRight(originrow,imagedata1){
            // 模四倍的偏移行数
            let relativep=originrow%(8*shiftrowsnum)
            // 颜色反转
            for(let i=0;i<imagedata1.width;i+=1){
                let pixel1=getPixel(imagedata1,originrow,i)
                setPixel(imagedata1,originrow,i,[255-pixel1[0],255-pixel1[1],255-pixel1[2],255])
            }
            // 上一半 对称
            if(relativep<4*shiftrowsnum){
                // 按照中间对称轴左右反转
                for(let i=0;i<Math.floor(imagedata1.width/2);i+=1){
                    let pixel1=getPixel(imagedata1,originrow,i)
                    let pixel2=getPixel(imagedata1,originrow,imagedata1.width-i-1)
                    setPixel(imagedata1,originrow,i,pixel2)
                    setPixel(imagedata1,originrow,imagedata1.width-i-1,pixel1)
                }
            }

        }
        // 向左偏移
        function shiftLeft(originrow,imagedata1){
            // 模四倍的偏移行数
            let relativep=originrow%(8*shiftrowsnum)
            // 颜色反转
            for(let i=0;i<imagedata1.width;i+=1){
                let pixel1=getPixel(imagedata1,originrow,i)
                setPixel(imagedata1,originrow,i,[255-pixel1[0],255-pixel1[1],255-pixel1[2],255])
            }
            // 上一半 对称
            if(relativep<4*shiftrowsnum){
                // 按照中间对称轴左右反转
                for(let i=0;i<Math.floor(imagedata1.width/2);i+=1){
                    let pixel1=getPixel(imagedata1,originrow,i)
                    let pixel2=getPixel(imagedata1,originrow,imagedata1.width-i-1)
                    setPixel(imagedata1,originrow,i,pixel2)
                    setPixel(imagedata1,originrow,imagedata1.width-i-1,pixel1)
                }
            }
        }

        // =============初始化==============
        var videostate = "pause"
        var player1 = null
        var player2 = null
        
        var logtick = 0
        window.addEventListener("load", function () {

            /**
             * 从视频中提取帧
             */
            function extractFrames() {
                const canvasStream1 = document.querySelector("#stream-video1_html5_api")
                const canvasStream2 = document.querySelector("#stream-video2_html5_api")
                const canvasVideo1 = document.querySelector("#canvas-video1")
                const canvasVideo2 = document.querySelector("#canvas-video2")
                const canvasVideoctx1 = canvasVideo1.getContext("2d");
                const canvasVideoctx2 = canvasVideo2.getContext("2d");
                const canvasForwardVideo1 = document.querySelector("#forward-video1")
                const canvasForwardctx1 = canvasForwardVideo1.getContext("2d");
                const canvasBackwardVideo1 = document.querySelector("#backward-video1")
                const canvasBackwardctx1 = canvasBackwardVideo1.getContext("2d");
                // 获取当前视频信息
                const videoWidth1 = canvasStream1.videoWidth;
                const videoHeight1 = canvasStream1.videoHeight;
                const videoWidth2 = canvasStream2.videoWidth;
                const videoHeight2 = canvasStream2.videoHeight;
                // 如果第一次运行此函数，需要设置canvas的宽高
                if (logtick == 0) {
                    canvasVideo1.setAttribute("width", videoWidth1);
                    canvasVideo1.setAttribute("height", videoHeight1);
                    canvasVideo2.setAttribute("width", videoWidth2);
                    canvasVideo2.setAttribute("height", videoHeight2);
                }
                // 获取画布
                // 绘制当前视频的画面到canvas
                canvasVideoctx1.drawImage(canvasStream1, 0, 0, videoWidth1, videoHeight1);
                canvasVideoctx2.drawImage(canvasStream2, 0, 0, videoWidth2, videoHeight2);
                // 获取当前视频的像素信息
                let imagedata1 = canvasVideoctx1.getImageData(0, 0, videoWidth1, videoHeight1)
                let imagedata2 = canvasVideoctx2.getImageData(0, 0, videoWidth2, videoHeight2)
                // 对像素进行正向处理（加密）
                const forwarddata1 = forwardProcessData([imagedata1, imagedata2])
                // 将forwarddata1放canvas中
                // 根据实际清晰度不同，视频画面大小不同
                // 如果第一次运行此函数，需要设置canvas的宽高
                if (logtick == 0) {
                    canvasForwardVideo1.setAttribute("width", forwarddata1.width);
                    canvasForwardVideo1.setAttribute("height", forwarddata1.height);
                    console.log(forwarddata1)
                }
                canvasForwardctx1.putImageData(forwarddata1, 0, 0);
                // 对像素进行逆向处理（解密）
                const backwarddata1 = backwardProcessData([middleProcessData([forwarddata1])])
                // 将backwarddata1放canvas中
                // 根据实际清晰度不同，视频画面大小不同
                // 如果第一次运行此函数，需要设置canvas的宽高
                if (logtick == 0) {
                    canvasBackwardVideo1.setAttribute("width", backwarddata1.width);
                    canvasBackwardVideo1.setAttribute("height", backwarddata1.height);
                }
                canvasBackwardctx1.putImageData(backwarddata1, 0, 0);
            }
            // 每隔40ms调用一次处理
            setInterval(() => {
                if (videostate === "play") {
                    // 计算调用extractFrames耗费的时间
                    let start = new Date().getTime()
                    extractFrames();
                    let end = new Date().getTime()
                    if(logtick%50==0){
                        console.log("extractFrames耗费时间：" + (end - start) + "ms")
                    }
                    logtick += 1;
                }
            }, 40)
            // 新建播放器
            player1 = videojs('stream-video1', {}, function playerReady() {
                this.volume(0)
                this.on("play", () => {
                    console.log("play1")
                    videostate = "play"
                })
                this.on("pause", () => {
                    console.log("pause1")
                    videostate = "pause"
                })
            });
            player2 = videojs('stream-video2', {}, function playerReady() {
                this.volume(0)
                this.on("play", () => {
                    console.log("play2")
                    videostate = "play"
                })
                this.on("pause", () => {
                    console.log("pause2")
                    videostate = "pause"
                })
            });
            function makefullscreen(idstr){
                const elem = document.getElementById(idstr);
                if (elem.requestFullscreen) {
                    elem.requestFullscreen();
                } else if (elem.mozRequestFullScreen) {
                    /* Firefox */
                    elem.mozRequestFullScreen();
                } else if (elem.webkitRequestFullscreen) {
                    /* Chrome, Safari and Opera */
                    elem.webkitRequestFullscreen();
                } else if (elem.msRequestFullscreen) {
                    /* IE/Edge */
                    elem.msRequestFullscreen();
                }
            }
            // 点击使canvas全屏
            document.getElementById("backward-video1").onclick = function () {
                makefullscreen("backward-video1")
            };
            document.getElementById("canvas-video1").onclick = function () {
                makefullscreen("canvas-video1")
            };
            document.getElementById("canvas-video2").onclick = function () {
                makefullscreen("canvas-video2")
            };
            document.getElementById("forward-video1").onclick = function () {
                makefullscreen("forward-video1")
            };
            document.getElementById("backward-video1").onclick = function () {
                makefullscreen("backward-video1")
            };
        })





    </script>
</body>

</html>