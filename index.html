<html>

<head>
    <title>HLS播放</title>
    <script src="https://vjs.zencdn.net/7.4.1/video.js"></script>
    <link href="https://vjs.zencdn.net/7.4.1/video-js.css" rel="stylesheet">
    <style type="text/css">
    </style>
</head>

<body>
    <!-- 纯净拉流 -->
    <h2>纯净直播流1</h2>
    <video-js id="stream-video1" width="1280" height="720" class="vjs-default-skin" controls>
        <!-- <source
            src="R6.mp4"
            type="video/mp4"> -->
        <source
        src="https://d1--cn-gotcha101.bilivideo.com/live-bvc/334644/live_7734200_bs_7236416_1500.m3u8?expires=1684253692&len=0&oi=827633949&pt=h5&qn=150&trid=10035a71d53b4f8b40f3b441a2c9808e56bf&sigparams=cdn,expires,len,oi,pt,qn,trid&cdn=cn-gotcha01&sign=29abdb34280abd39cd865cd52fe176ea&sk=8850a2b8817f9dbc872b6389c642a426&p2p_type=0&sl=10&free_type=0&mid=0&pp=rtmp&source=onetier&trace=10&site=d471bf630851c115b2af5f07450a540d&order=1"
        type="application/x-mpegURL">
    </video-js>
    <h2>纯净直播流2</h2>
    <video-js id="stream-video2" width="1280" height="720" class="vjs-default-skin" controls>
        <source
            src="https://d1--cn-gotcha101.bilivideo.com/live-bvc/249439/live_474595627_50840492_1500.m3u8?expires=1684265012&len=0&oi=827633949&pt=h5&qn=150&trid=10038fd26213fa4a4ede8d15f2b0bb6eb439&sigparams=cdn,expires,len,oi,pt,qn,trid&cdn=cn-gotcha01&sign=a54edecf5a69e81f3af02f1dd98ae87b&sk=1304f646dfeb4df8b6e7ff33c167d3ad52dc28d2b434c49b202f46923d102069&p2p_type=0&sl=9&free_type=0&mid=0&pp=rtmp&source=onetier&trace=10&site=b0ab15ca65cfcca5785fd6c575fa5c8f&order=1"
            type="application/x-mpegURL">
    </video-js>

    <h2>直播流1的canvas</h2>
    <canvas id="canvas-video1"></canvas>
    <h2>直播流2的canvas</h2>
    <canvas id="canvas-video2"></canvas>

    <!-- 通常是加密后 -->
    <h2>正向处理结果</h2>
    <canvas id="forward-video1"></canvas>
    <!-- 通常是解密后 -->
    <h2>反向处理结果(已模拟传输时损失)</h2>
    <canvas id="backward-video1">
    </canvas>




    <script>
        const maxcolorshiftpercent=0.7//偏移的颜色最多占据剩余颜色空间的百分点【0.0~1.0】
        const frame=25//每秒帧数
        const mocktransfer=false//模拟传输杂色
        /**
        * 正向处理像素信息（加密）
        * @param {Array} imagedatalist 一个包含两个图像的数组，分别是直播流1和直播流2的图像
        * @returns 一个图像
        */
        function forwardProcessData(imagedatalist) {
            let imagedata1 = imagedatalist[0]
            let imagedata2 = imagedatalist[1]
            let pindex=0
            for(let i=0;i<imagedata1.height;i+=2){
                for(let j=0;j<imagedata1.width;j+=1){
                    // 获取视频1每两行的第一行的每三个像素点中的第一个像素点,n%3=0
                    if(j%3==0){
                        pindex=getPixelIndex(imagedata1,i,j)
                    }
                    // 把视频2每两行的第一行的每三个像素点复制到第二行的每三个像素点，三个像素的R，G，B颜色分别空间放缩对应上面pindex的R，G，B
                    setPixel(imagedata2,i+1,j,
                        shiftcolor( imagedata2.data[getPixelIndex(imagedata2,i,j)], imagedata1.data[pindex]),
                        shiftcolor( imagedata2.data[getPixelIndex(imagedata2,i,j)+1],imagedata1.data[pindex+1]),
                        shiftcolor( imagedata2.data[getPixelIndex(imagedata2,i,j)+2],imagedata1.data[pindex+2]))
                }
            }
            return imagedata2
        }


        /**
         * 中间处理像素信息，模拟传输过程
         * @param {Array} imagedatalist 一个包含一个图像的数组，是正向处理后的图像
         * @returns 一个图像
         */
        function middleProcessData(imagedatalist){
            let imagedata1=imagedatalist[0]
            if(!mocktransfer){
                return imagedata1
            }
            // 加点噪声
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += 1) {
                    let random = Math.random()
                    if (random < 0.0001) {
                        setPixel(imagedata1, j, i, 255, 255, 255)
                    }
                }
            }
            // 在随机的区域偏色
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += 1) {
                    let random = Math.random()
                    if (random < 0.001) {
                        const randomblur = Math.floor(Math.random() * 10)
                        const index1 = (j * imagedata1.width + i) * 4
                        setPixel(imagedata1, j, i, imagedata1.data[index1] + randomblur, imagedata1.data[index1 + 1] + randomblur, imagedata1.data[index1 + 2] + randomblur)
                    }
                }
            }
            // 在随机的区域取附近的点的值代替
            for (let i = 0; i < imagedata1.width; i += 1) {
                for (let j = 0; j < imagedata1.height; j += 1) {
                    let random = Math.random()
                    if (random < 0.001) {
                        let randomblur = Math.floor(Math.random() * 10)
                        let randomx = Math.floor(Math.random() * 10)
                        let randomy = Math.floor(Math.random() * 10)
                        let index2 = ((j + randomy) * imagedata1.width + i + randomx) * 4
                        try {
                            setPixel(imagedata1, j, i, imagedata1.data[index2], imagedata1.data[index2 + 1], imagedata1.data[index2 + 2])
                        } catch (error) {
                            
                        }
                        
                    }
                }
            }

            return imagedata1
        }

        /**
         * 反向处理像素信息（解密）
         * @param {Array} imagedatalist 一个包含一个图像的数组，是传输过后的正向处理后的图像
         * @returns 一个图像
         */
        function backwardProcessData(imagedatalist) {
            let imagedata1 = imagedatalist[0]
            for(let i=0;i<imagedata1.height;i+=2){
                let r=0,g=0,b=0
                for(let j=0;j<imagedata1.width;j+=1){
                    // 获取视频1每两行的第二行的每三个像素点，根据其获取隐藏的视频的一个像素本真R，G，B值
                    if(j%3==0){
                        // R
                        r=shiftcolorback(imagedata1.data[getPixelIndex(imagedata1,i+1,j)],imagedata1.data[getPixelIndex(imagedata1,i,j)])
                    }
                    if(j%3==1){
                        // G
                        g=shiftcolorback(imagedata1.data[getPixelIndex(imagedata1,i+1,j)+1],imagedata1.data[getPixelIndex(imagedata1,i,j)+1])
                    }
                    if(j%3==2){
                        // B
                        b=shiftcolorback(imagedata1.data[getPixelIndex(imagedata1,i+1,j)+2],imagedata1.data[getPixelIndex(imagedata1,i,j)+2])
                    }
                    // 赋值
                    if(j%3==0 && j!=0){
                        for(let k=j-3;k<j;k++){
                            setPixel(imagedata1,i,k,r,g,b)
                            setPixel(imagedata1,i+1,k,r,g,b)

                        }
                    }
                }
            }

            return imagedata1
        }

        function getPixelIndex(imagedata, row, col) {
            let index = (row * imagedata.width + col) * 4
            return index
        }

        function setPixel(imagedata, row, col, r, g, b){
            let index = (row * imagedata.width + col) * 4
            imagedata.data[index] = r
            imagedata.data[index + 1] = g
            imagedata.data[index + 2] = b
            imagedata.data[index + 3] = 255
        }

        /**
         * 把basevalue（本真）根据sidevalue（隐藏）放缩，得到mixvalue
         */
        function shiftcolor(basevalue, sidevalue){
            return Math.floor(basevalue*sidevalue/255) // 所占空间
            // return Math.floor((255-basevalue)*sidevalue/255+basevalue) // 剩余空间
        }

        /**
         * 把mixvalue（混合后的）根据basevalue（本真）放缩回sidevalue（隐藏）
         */
        function shiftcolorback(mixvalue, basevalue){
            return Math.floor(255*mixvalue/basevalue) // 所占空间
            // return Math.floor((mixvalue-basevalue)*255/(255-basevalue)) // 剩余空间
        }
        
        // =============初始化==============
        var videostate = "pause"
        var player1 = null
        var player2 = null
        
        var logtick = -1
        window.addEventListener("load", function () {

            /**
             * 从视频中提取帧
             */
            function extractFrames() {
                const canvasStream1 = document.querySelector("#stream-video1_html5_api")
                const canvasStream2 = document.querySelector("#stream-video2_html5_api")
                const canvasVideo1 = document.querySelector("#canvas-video1")
                const canvasVideo2 = document.querySelector("#canvas-video2")
                const canvasVideoctx1 = canvasVideo1.getContext("2d");
                const canvasVideoctx2 = canvasVideo2.getContext("2d");
                const canvasForwardVideo1 = document.querySelector("#forward-video1")
                const canvasForwardctx1 = canvasForwardVideo1.getContext("2d");
                const canvasBackwardVideo1 = document.querySelector("#backward-video1")
                const canvasBackwardctx1 = canvasBackwardVideo1.getContext("2d");
                // 获取当前视频信息
                const videoWidth1 = canvasStream1.videoWidth;
                const videoHeight1 = canvasStream1.videoHeight;
                const videoWidth2 = canvasStream2.videoWidth;
                const videoHeight2 = canvasStream2.videoHeight;
                // 如果第一次运行此函数，需要设置canvas的宽高
                if (logtick == 0) {
                    canvasVideo1.setAttribute("width", videoWidth1);
                    canvasVideo1.setAttribute("height", videoHeight1);
                    canvasVideo2.setAttribute("width", videoWidth2);
                    canvasVideo2.setAttribute("height", videoHeight2);
                }
                // 获取画布
                // 绘制当前视频的画面到canvas
                canvasVideoctx1.drawImage(canvasStream1, 0, 0, videoWidth1, videoHeight1);
                canvasVideoctx2.drawImage(canvasStream2, 0, 0, videoWidth2, videoHeight2);
                // 获取当前视频的像素信息
                let imagedata1 = canvasVideoctx1.getImageData(0, 0, videoWidth1, videoHeight1)
                let imagedata2 = canvasVideoctx2.getImageData(0, 0, videoWidth2, videoHeight2)
                // 对像素进行正向处理（加密）
                const forwarddata1 = forwardProcessData([imagedata1, imagedata2])
                // 将forwarddata1放canvas中
                // 根据实际清晰度不同，视频画面大小不同
                // 如果第一次运行此函数，需要设置canvas的宽高
                if (logtick == 0) {
                    console.log("视频1长宽：" + forwarddata1.width + " " + forwarddata1.height)
                    console.log("视频2长宽：" + imagedata2.width + " " + imagedata2.height)
                    canvasForwardVideo1.setAttribute("width", forwarddata1.width);
                    canvasForwardVideo1.setAttribute("height", forwarddata1.height);
                    console.log(forwarddata1)
                }
                canvasForwardctx1.putImageData(forwarddata1, 0, 0);
                // 对像素进行逆向处理（解密）
                const backwarddata1 = backwardProcessData([middleProcessData([forwarddata1])])
                // 将backwarddata1放canvas中
                // 根据实际清晰度不同，视频画面大小不同
                // 如果第一次运行此函数，需要设置canvas的宽高
                if (logtick == 0) {
                    canvasBackwardVideo1.setAttribute("width", backwarddata1.width);
                    canvasBackwardVideo1.setAttribute("height", backwarddata1.height);
                }
                canvasBackwardctx1.putImageData(backwarddata1, 0, 0);
            }
            // 每隔40ms调用一次处理
            setInterval(() => {
                if (videostate === "play") {
                    // 计算调用extractFrames耗费的时间
                    let start = new Date().getTime()
                    extractFrames();
                    let end = new Date().getTime()
                    if(logtick%50==0){
                        console.log("extractFrames耗费时间：" + (end - start) + "ms")
                    }
                    logtick += 1;
                }
            }, Math.floor(1000/frame))
            // 新建播放器
            player1 = videojs('stream-video1', {}, function playerReady() {
                this.volume(0)
                this.on("play", () => {
                    console.log("play1")
                    videostate = "play"
                })
                this.on("pause", () => {
                    console.log("pause1")
                    videostate = "pause"
                })
            });
            player2 = videojs('stream-video2', {}, function playerReady() {
                this.volume(0)
                this.on("play", () => {
                    console.log("play2")
                    videostate = "play"
                })
                this.on("pause", () => {
                    console.log("pause2")
                    videostate = "pause"
                })
            });
            function makefullscreen(idstr){
                const elem = document.getElementById(idstr);
                if (elem.requestFullscreen) {
                    elem.requestFullscreen();
                } else if (elem.mozRequestFullScreen) {
                    /* Firefox */
                    elem.mozRequestFullScreen();
                } else if (elem.webkitRequestFullscreen) {
                    /* Chrome, Safari and Opera */
                    elem.webkitRequestFullscreen();
                } else if (elem.msRequestFullscreen) {
                    /* IE/Edge */
                    elem.msRequestFullscreen();
                }
            }
            // 点击使canvas全屏
            document.getElementById("backward-video1").onclick = function () {
                makefullscreen("backward-video1")
            };
            document.getElementById("canvas-video1").onclick = function () {
                makefullscreen("canvas-video1")
            };
            document.getElementById("canvas-video2").onclick = function () {
                makefullscreen("canvas-video2")
            };
            document.getElementById("forward-video1").onclick = function () {
                makefullscreen("forward-video1")
            };
            document.getElementById("backward-video1").onclick = function () {
                makefullscreen("backward-video1")
            };
        })





    </script>
</body>

</html>